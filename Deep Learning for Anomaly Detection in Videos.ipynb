{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow==2.1.0\nimport tensorflow as tf\nprint(tf.__version__)","execution_count":9,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: tensorflow==2.1.0 in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.9.0)\nRequirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.2.2)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.34.2)\nRequirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (2.1.0)\nRequirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.8.1)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.1.0)\nRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.2.0)\nRequirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.0.8)\nRequirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.1.0)\nRequirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.18.1)\nRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.11.2)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.28.1)\nRequirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (2.1.1)\nRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.4.1)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.14.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (3.2.1)\nRequirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (3.11.4)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (46.1.3.post20200325)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.14.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.2.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.4.5.1)\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.1)\nRequirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n2.1.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.test.is_gpu_available()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: |https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":11,"outputs":[{"output_type":"stream","text":"/kaggle/input/anomaly-test-minibatches/minibatches/minibatch34.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch54.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch16.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch47.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch0.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch13.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch25.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch49.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch18.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch59.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch67.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch38.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch9.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch48.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch66.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch46.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch10.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch1.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch63.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch21.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch55.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch52.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch53.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch50.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch15.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch2.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch26.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch30.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch22.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch12.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch42.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch61.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch32.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch8.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch58.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch36.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch20.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch40.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch37.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch57.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch5.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch27.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch24.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch43.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch28.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch64.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch65.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch4.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch45.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch44.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch11.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch35.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch3.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch39.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch51.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch17.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch29.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch41.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch14.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch56.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch33.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch31.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch62.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch19.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch60.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch6.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch23.npz\n/kaggle/input/anomaly-test-minibatches/minibatches/minibatch7.npz\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data57.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data59.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data56.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data40.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data47.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data32.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data37.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data48.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data28.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data38.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data34.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data25.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data45.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data58.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data53.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data43.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data31.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data60.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data33.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data51.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data46.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data30.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data41.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data49.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data42.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data27.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data18.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data44.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data52.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data0.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data50.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data39.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data35.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data55.tfrecord\n/kaggle/input/anomaly-detection-dev-set/ValidSet/Data54.tfrecord\n/kaggle/input/weightsanomaly-detection-04/weights_epoch4.index\n/kaggle/input/weightsanomaly-detection-04/weights_epoch0.data-00001-of-00002\n/kaggle/input/weightsanomaly-detection-04/weights_epoch0.index\n/kaggle/input/weightsanomaly-detection-04/weights_epoch1.data-00001-of-00002\n/kaggle/input/weightsanomaly-detection-04/weights_epoch0.data-00000-of-00002\n/kaggle/input/weightsanomaly-detection-04/weights_epoch4.data-00000-of-00002\n/kaggle/input/weightsanomaly-detection-04/weights_epoch3.index\n/kaggle/input/weightsanomaly-detection-04/weights_epoch3.data-00000-of-00002\n/kaggle/input/weightsanomaly-detection-04/weights_epoch4.data-00001-of-00002\n/kaggle/input/weightsanomaly-detection-04/weights_epoch2.data-00000-of-00002\n/kaggle/input/weightsanomaly-detection-04/weights_epoch2.data-00001-of-00002\n/kaggle/input/weightsanomaly-detection-04/weights_epoch1.data-00000-of-00002\n/kaggle/input/weightsanomaly-detection-04/weights_epoch2.index\n/kaggle/input/weightsanomaly-detection-04/weights_epoch3.data-00001-of-00002\n/kaggle/input/weightsanomaly-detection-04/checkpoint\n/kaggle/input/weightsanomaly-detection-04/weights_epoch1.index\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data9.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data22.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data40.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data5.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data32.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data37.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data20.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data15.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data7.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data28.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data38.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data34.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data26.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data25.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data24.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data4.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data10.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data23.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data16.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data3.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data11.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data8.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data31.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data29.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data2.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data36.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data13.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data33.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data6.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data21.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data30.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data1.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data41.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data19.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data14.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data42.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data27.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data18.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data0.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data39.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data17.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data12.tfrecord\n/kaggle/input/ucf-crime-training-subset/tfrecords2/Data35.tfrecord\n/kaggle/input/saved-models/weights_epoch13.h5\n/kaggle/input/saved-models/weights_epoch35.h5\n/kaggle/input/saved-models/weights_epoch4.h5\n/kaggle/input/saved-models/weights_epoch25.h5\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n# Corresponding changes are to be made here\n# if the feature description in tf2_preprocessing.py\n# is changed\nfeature_description = {\n    'segment': tf.io.FixedLenFeature([], tf.string),\n    'file': tf.io.FixedLenFeature([], tf.string),\n    'num': tf.io.FixedLenFeature([], tf.int64)\n}\n\n\ndef build_dataset(dir_path, batch_size=16, file_buffer=500*1024*1024,\n                  shuffle_buffer=1024, label=1):\n    '''Return a tf.data.Dataset based on all TFRecords in dir_path\n    Args:\n    dir_path: path to directory containing the TFRecords\n    batch_size: size of batch ie #training examples per element of the dataset\n    file_buffer: for TFRecords, size in bytes\n    shuffle_buffer: #examples to buffer while shuffling\n    label: target label for the example\n    '''\n    # glob pattern for files\n    file_pattern = os.path.join(dir_path, '*.tfrecord')\n    # stores shuffled filenames\n    file_ds = tf.data.Dataset.list_files(file_pattern)\n    # read from multiple files in parallel\n    ds = tf.data.TFRecordDataset(file_ds,\n                                 num_parallel_reads=tf.data.experimental.AUTOTUNE,\n                                 buffer_size=file_buffer)\n    # randomly draw examples from the shuffle buffer\n    ds = ds.shuffle(buffer_size=shuffle_buffer,\n                    reshuffle_each_iteration=True)\n    # batch the examples\n    # dropping remainder for now, trouble when parsing - adding labels\n    ds = ds.batch(batch_size, drop_remainder=True)\n    # parse the records into the correct types\n    ds = ds.map(lambda x: _my_parser(x, label, batch_size),\n                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n    return ds\n\n\ndef _my_parser(examples, label, batch_size):\n    '''Parses a batch of serialised tf.train.Example(s)\n    Args:\n    example: a batch serialised tf.train.Example(s)\n    Returns:\n    a tuple (segment, label)\n    where segment is a tensor of shape (#in_batch, #frames, h, w, #channels)\n    '''\n    # ex will be a tensor of serialised tensors\n    ex = tf.io.parse_example(examples, features=feature_description)\n    ex['segment'] = tf.map_fn(lambda x: _parse_segment(x),\n                              ex['segment'], dtype=tf.uint8)\n    # ignoring filename and segment num for now\n    # returns a tuple (tensor1, tensor2)\n    # tensor1 is a batch of segments, tensor2 is the corresponding labels\n    return (ex['segment'], tf.fill((batch_size, 1), label))\n\n\ndef _parse_segment(segment):\n    '''Parses a segment and returns it as a tensor\n    A segment is a serialised tensor of a number of encoded jpegs\n    '''\n    # now a tensor of encoded jpegs\n    parsed = tf.io.parse_tensor(segment, out_type=tf.string)\n    # now a tensor of shape (#frames, h, w, #channels)\n    parsed = tf.map_fn(lambda y: tf.io.decode_jpeg(y), parsed, dtype=tf.uint8)\n    return parsed\n\n\ndef display_segment(segment, batch_size):\n    fig = plt.figure(figsize=(16, 16))\n    columns = int(math.sqrt(batch_size))\n    rows = math.ceil(batch_size / float(columns))\n    for i in range(1, columns*rows + 1):\n        img = segment[i-1]\n        fig.add_subplot(rows, columns, i)\n        plt.imshow(img)\n    plt.show()\nfeature_description = {\n    'segment': tf.io.FixedLenFeature([], tf.string),\n    'file': tf.io.FixedLenFeature([], tf.string),\n    'num': tf.io.FixedLenFeature([], tf.int64),\n    'label': tf.io.FixedLenFeature([], tf.int64)\n}\n\n\ndef build_test_dataset(dir_path, batch_size=16, file_buffer=500*1024*1024):\n    '''Return a tf.data.Dataset based on all TFRecords in dir_path\n    Args:\n    dir_path: path to directory containing the TFRecords\n    batch_size: size of batch ie #training examples per element of the dataset\n    file_buffer: for TFRecords, size in bytes\n    label: target label for the example\n    '''\n    # glob pattern for files\n    file_pattern = os.path.join(dir_path, '*.tfrecord')\n    # stores shuffled filenames\n    file_ds = tf.data.Dataset.list_files(file_pattern)\n    # read from multiple files in parallel\n    ds = tf.data.TFRecordDataset(file_ds,\n                                 num_parallel_reads=tf.data.experimental.AUTOTUNE,\n                                 buffer_size=file_buffer)\n    # batch the examples\n    # dropping remainder for now, trouble when parsing - adding labels\n    ds = ds.batch(batch_size, drop_remainder=True)\n    # parse the records into the correct types\n    ds = ds.map(lambda x: _my_test_parser(x, batch_size=batch_size),\n                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n    return ds\n\ndef _my_test_parser(examples, batch_size):\n    '''Parses a batch of serialised tf.train.Example(s)\n    Args:\n    example: a batch serialised tf.train.Example(s)\n    Returns:\n    a tuple (segment, label)\n    where segment is a tensor of shape (#in_batch, #frames, h, w, #channels)\n    '''\n    # ex will be a tensor of serialised tensors\n    ex = tf.io.parse_example(examples, features=feature_description)\n    ex['segment'] = tf.map_fn(lambda x: _parse_segment(x),\n                              ex['segment'], dtype=tf.uint8)\n    # ignoring filename and segment num for now\n    # returns a tuple (tensor1, tensor2)\n    # tensor1 is a batch of segments, tensor2 is the corresponding labels\n    return (ex['segment'], ex['label'])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras.layers import (Input, Activation,\n                                     BatchNormalization, Conv3D,\n                                     LeakyReLU, Conv3DTranspose)\nfrom tensorflow.keras.layers import MaxPool3D\nfrom tensorflow.keras.models import Model\nimport tensorflow.keras.backend as K\n\n\ndef AutoEncoderModel():\n    # encoder\n    X_input = Input((16, 128, 128, 3))\n\n    X = Conv3D(32, 3, padding='same')(X_input)\n    X = BatchNormalization()(X)\n    X = LeakyReLU()(X)\n    X = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(X)\n    # current shape is 8x64x64x32\n    X = Conv3D(48, 3, padding='same')(X)\n    X = BatchNormalization()(X)\n    X = LeakyReLU()(X)\n    X = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(X)\n    # current shape is 4x32x32x48\n    X = Conv3D(64, 3, padding='same')(X)\n    X = BatchNormalization()(X)\n    X = LeakyReLU()(X)\n    X = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(X)\n    # current shape is 2x16x16x64\n    X = Conv3D(64, 3, padding='same')(X)\n    X = BatchNormalization()(X)\n    X = LeakyReLU()(X)\n    X = MaxPool3D(pool_size=(2, 2, 2), strides=(1, 1, 1), padding='same')(X)\n    # current shape is 2x16x16x64\n    # decoder\n\n    X = Conv3DTranspose(48, 2, strides=(2, 2, 2), padding='valid')(X)\n    X = BatchNormalization()(X)\n    X = LeakyReLU()(X)\n    # current shape is 4x32x32x48\n    X = Conv3DTranspose(32, 2, strides=(2, 2, 2), padding='valid')(X)\n    X = BatchNormalization()(X)\n    X = LeakyReLU()(X)\n    # current shape is 8x64x64x32\n    X = Conv3DTranspose(32, 2, strides=(2, 2, 2), padding='valid')(X)\n    X = BatchNormalization()(X)\n    X = LeakyReLU()(X)\n    # current shape is 16x128x128x32\n    X = Conv3D(3, 3, strides=(1, 1, 1), padding='same')(X)\n    X = Activation('sigmoid')(X)\n    # current shape is 16x128x128x3\n\n    model = Model(inputs=X_input, outputs=X, name='AutoEncoderModel')\n    return model\n\n\ndef custom_loss(new, original):\n    reconstruction_error = K.mean(K.square(new-original))\n    return reconstruction_error\n\nautoEncoderModel = AutoEncoderModel()\nopt = keras.optimizers.Adam(lr=0.001)\nautoEncoderModel.compile(\n    loss=custom_loss, optimizer=opt, metrics=['accuracy'])\nprint(autoEncoderModel.summary())","execution_count":13,"outputs":[{"output_type":"stream","text":"Model: \"AutoEncoderModel\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_6 (InputLayer)         [(None, 16, 128, 128, 3)] 0         \n_________________________________________________________________\nconv3d_18 (Conv3D)           (None, 16, 128, 128, 32)  2624      \n_________________________________________________________________\nbatch_normalization_24 (Batc (None, 16, 128, 128, 32)  128       \n_________________________________________________________________\nleaky_re_lu_14 (LeakyReLU)   (None, 16, 128, 128, 32)  0         \n_________________________________________________________________\nmax_pooling3d_16 (MaxPooling (None, 8, 64, 64, 32)     0         \n_________________________________________________________________\nconv3d_19 (Conv3D)           (None, 8, 64, 64, 48)     41520     \n_________________________________________________________________\nbatch_normalization_25 (Batc (None, 8, 64, 64, 48)     192       \n_________________________________________________________________\nleaky_re_lu_15 (LeakyReLU)   (None, 8, 64, 64, 48)     0         \n_________________________________________________________________\nmax_pooling3d_17 (MaxPooling (None, 4, 32, 32, 48)     0         \n_________________________________________________________________\nconv3d_20 (Conv3D)           (None, 4, 32, 32, 64)     83008     \n_________________________________________________________________\nbatch_normalization_26 (Batc (None, 4, 32, 32, 64)     256       \n_________________________________________________________________\nleaky_re_lu_16 (LeakyReLU)   (None, 4, 32, 32, 64)     0         \n_________________________________________________________________\nmax_pooling3d_18 (MaxPooling (None, 2, 16, 16, 64)     0         \n_________________________________________________________________\nconv3d_21 (Conv3D)           (None, 2, 16, 16, 64)     110656    \n_________________________________________________________________\nbatch_normalization_27 (Batc (None, 2, 16, 16, 64)     256       \n_________________________________________________________________\nleaky_re_lu_17 (LeakyReLU)   (None, 2, 16, 16, 64)     0         \n_________________________________________________________________\nmax_pooling3d_19 (MaxPooling (None, 2, 16, 16, 64)     0         \n_________________________________________________________________\nconv3d_transpose_6 (Conv3DTr (None, 4, 32, 32, 48)     24624     \n_________________________________________________________________\nbatch_normalization_28 (Batc (None, 4, 32, 32, 48)     192       \n_________________________________________________________________\nleaky_re_lu_18 (LeakyReLU)   (None, 4, 32, 32, 48)     0         \n_________________________________________________________________\nconv3d_transpose_7 (Conv3DTr (None, 8, 64, 64, 32)     12320     \n_________________________________________________________________\nbatch_normalization_29 (Batc (None, 8, 64, 64, 32)     128       \n_________________________________________________________________\nleaky_re_lu_19 (LeakyReLU)   (None, 8, 64, 64, 32)     0         \n_________________________________________________________________\nconv3d_transpose_8 (Conv3DTr (None, 16, 128, 128, 32)  8224      \n_________________________________________________________________\nbatch_normalization_30 (Batc (None, 16, 128, 128, 32)  128       \n_________________________________________________________________\nleaky_re_lu_20 (LeakyReLU)   (None, 16, 128, 128, 32)  0         \n_________________________________________________________________\nconv3d_22 (Conv3D)           (None, 16, 128, 128, 3)   2595      \n_________________________________________________________________\nactivation_10 (Activation)   (None, 16, 128, 128, 3)   0         \n=================================================================\nTotal params: 286,851\nTrainable params: 286,211\nNon-trainable params: 640\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.layers import Flatten,Dense\nfrom tensorflow.keras import Sequential\ndef create_discriminator_model():\n\n    X_input = Input((16, 128, 128, 3))\n\n    # not sure about the axis in batch norm\n    # do we also add dropout after batchnorm/pooling?\n\n    # Convolutional Layers\n    # changed the no of filters\n    model= Sequential()\n    model.add(Conv3D(filters=48, kernel_size=(2, 2, 2), padding=\"same\",input_shape=(16, 128, 128, 3)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n\n    model.add(Conv3D(filters=64, kernel_size=(2, 2, 2), padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n\n    model.add(Conv3D(filters=128, kernel_size=(2, 2, 2), padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n\n    model.add(Conv3D(filters=128, kernel_size=(2, 2, 2), padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n\n    # to add the 5th layer change the cap to 32 frames\n\n    # X=Conv3D(filters=256,kernel_size=(2,2,2),padding=\"same\")(X)\n    # X=BatchNormalization()(X)\n    # X=Activation('relu')(X)\n    # X=MaxPool3D(pool_size=(2,2,2),strides=(2,2,2))(X)\n\n    # Fully connected layers\n\n    model.add(Flatten())\n\n    model.add(Dense(256, activation='relu'))\n    # add batch norm to dense layer\n    model.add(BatchNormalization())\n    # activation done with loss fn\n    # for numerical stability\n    model.add(Dense(1, activation='sigmoid'))\n\n    return model\n\ndiscriminator = create_discriminator_model()\nopt = keras.optimizers.Adam(lr=0.001)\nloss = BinaryCrossentropy()\ndiscriminator.compile(loss=loss,\n                      optimizer=opt,\n                      metrics=['accuracy'])\nprint(discriminator.summary())\n","execution_count":14,"outputs":[{"output_type":"stream","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv3d_23 (Conv3D)           (None, 16, 128, 128, 48)  1200      \n_________________________________________________________________\nbatch_normalization_31 (Batc (None, 16, 128, 128, 48)  192       \n_________________________________________________________________\nactivation_11 (Activation)   (None, 16, 128, 128, 48)  0         \n_________________________________________________________________\nmax_pooling3d_20 (MaxPooling (None, 8, 64, 64, 48)     0         \n_________________________________________________________________\nconv3d_24 (Conv3D)           (None, 8, 64, 64, 64)     24640     \n_________________________________________________________________\nbatch_normalization_32 (Batc (None, 8, 64, 64, 64)     256       \n_________________________________________________________________\nactivation_12 (Activation)   (None, 8, 64, 64, 64)     0         \n_________________________________________________________________\nmax_pooling3d_21 (MaxPooling (None, 4, 32, 32, 64)     0         \n_________________________________________________________________\nconv3d_25 (Conv3D)           (None, 4, 32, 32, 128)    65664     \n_________________________________________________________________\nbatch_normalization_33 (Batc (None, 4, 32, 32, 128)    512       \n_________________________________________________________________\nactivation_13 (Activation)   (None, 4, 32, 32, 128)    0         \n_________________________________________________________________\nmax_pooling3d_22 (MaxPooling (None, 2, 16, 16, 128)    0         \n_________________________________________________________________\nconv3d_26 (Conv3D)           (None, 2, 16, 16, 128)    131200    \n_________________________________________________________________\nbatch_normalization_34 (Batc (None, 2, 16, 16, 128)    512       \n_________________________________________________________________\nactivation_14 (Activation)   (None, 2, 16, 16, 128)    0         \n_________________________________________________________________\nmax_pooling3d_23 (MaxPooling (None, 1, 8, 8, 128)      0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 8192)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 256)               2097408   \n_________________________________________________________________\nbatch_normalization_35 (Batc (None, 256)               1024      \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 257       \n=================================================================\nTotal params: 2,322,865\nTrainable params: 2,321,617\nNon-trainable params: 1,248\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nclass GAN():\n    def __init__(self, mini_batch_size):\n        self.image_shape=(16,128,128,3)\n        learning_rate=0.03\n        opt=keras.optimizers.Adam(lr=learning_rate)\n        opt1=keras.optimizers.Adam(lr=learning_rate)\n        opt_slow=keras.optimizers.Adam(lr=1)\n        #Build and compile the discriminator\n        self.discriminator=create_discriminator_model()\n        self.discriminator.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy',tf.keras.metrics.TruePositives(),tf.keras.metrics.FalsePositives(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.FalseNegatives()])\n        #Build and compile the generator\n        self.generator=AutoEncoderModel()\n        self.generator.compile(loss='mse',optimizer=opt_slow)\n\n        #the generator takes a video as input and generates a modified video\n        z = Input(shape=(self.image_shape))\n        img = self.generator(z)\n        self.discriminator.trainable = False\n        validity = self.discriminator(img)\n        self.combined = Model(z, validity)\n        self.combined.compile(loss='binary_crossentropy', optimizer=opt1,metrics=['accuracy'])\n        self.dir_path = '/kaggle/input/ucf-crime-training-subset/tfrecords2/'\n        self.ds = build_dataset(self.dir_path, batch_size=mini_batch_size,file_buffer=512*1024)\n    def train(self,epochs,mini_batch_size):\n        #this function will need to be added later\n        tf.summary.trace_off()\n        for epoch in range(epochs):\n            d_loss_sum=tf.zeros(2)\n            reconstruct_error_sum=0\n            g_loss_sum=tf.zeros(2)\n            no_of_minibatches=0\n            for minibatch,labels in self.ds:\n                # ---------------------\n                #  Train Discriminator\n                # ---------------------\n                #normalize inputs\n                no_of_minibatches+=1\n                minibatch=tf.cast(tf.math.divide(minibatch,255), tf.float32)\n                gen_vids=self.generator.predict(minibatch)\n                #might have to combine these to improve batch norm\n                d_loss_real=self.discriminator.train_on_batch(minibatch,tf.ones((mini_batch_size,1)))\n                d_loss_fake=self.discriminator.train_on_batch(gen_vids,tf.zeros((mini_batch_size,1)))\n                d_loss=0.5*tf.math.add(d_loss_real,d_loss_fake)\n                # ---------------------\n                #  Train Generator\n                # ---------------------\n                # The generator wants the discriminator to label the generated samples as valid (ones)\n                valid_y = tf.ones((mini_batch_size,1))\n                # Train the generator\n                g_loss = self.combined.train_on_batch(minibatch,valid_y)\n                reconstruct_error=self.generator.train_on_batch(minibatch,minibatch)\n                d_loss_sum+=d_loss\n                g_loss_sum+=g_loss\n                reconstruct_error_sum+=reconstruct_error\n            print(no_of_minibatches)\n            self.combined.save_weights('/kaggle/working/weights_epoch%d.h5' %(epoch+4))\n            g_loss=g_loss_sum/no_of_minibatches\n            d_loss=d_loss_sum/no_of_minibatches\n            reconstruct_error=reconstruct_error_sum/no_of_minibatches\n            # Plot the progress\n            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f, accuracy %.2f%% from which %f is combined loss and %f is reconstruction loss]\" % (epoch+4, d_loss[0], 100*d_loss[1], g_loss[0]+reconstruct_error,g_loss[1]*100,g_loss[0],reconstruct_error))\n        tf.summary.trace_on()\n    \n    def test(self,dev_set_path,mini_batch_size):\n        dev_set=build_test_dataset(dev_set_path,batch_size=mini_batch_size,file_buffer=500*1024)\n        no_of_minibatches=0\n        ans_final=tf.zeros(2)\n        for minibatch,labels in dev_set:\n            no_of_minibatches+=1\n            ans=self.discriminator.test_on_batch(minibatch,(labels==0),reset_metrics=False)\n            ans_final=ans\n        print(no_of_minibatches,ans_final[0],ans_final[1],ans_final[2],ans_final[3],ans_final[4],ans_final[5])\n                \n\n            \n        \n# BATCH SIZE WAS MOVED TO INIT, PROBABLY NOT THE BEST WAY TO DO IT\ngan = GAN(16)\ngan.combined.load_weights('../input/saved-models/weights_epoch35.h5')\nprint(gan.combined.summary())\nprint(gan.discriminator.summary())\nprint(gan.generator.summary())\n","execution_count":15,"outputs":[{"output_type":"stream","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_10 (InputLayer)        [(None, 16, 128, 128, 3)] 0         \n_________________________________________________________________\nAutoEncoderModel (Model)     (None, 16, 128, 128, 3)   286851    \n_________________________________________________________________\nsequential_3 (Sequential)    (None, 1)                 2322865   \n=================================================================\nTotal params: 2,609,716\nTrainable params: 286,211\nNon-trainable params: 2,323,505\n_________________________________________________________________\nNone\nModel: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv3d_27 (Conv3D)           (None, 16, 128, 128, 48)  1200      \n_________________________________________________________________\nbatch_normalization_36 (Batc (None, 16, 128, 128, 48)  192       \n_________________________________________________________________\nactivation_15 (Activation)   (None, 16, 128, 128, 48)  0         \n_________________________________________________________________\nmax_pooling3d_24 (MaxPooling (None, 8, 64, 64, 48)     0         \n_________________________________________________________________\nconv3d_28 (Conv3D)           (None, 8, 64, 64, 64)     24640     \n_________________________________________________________________\nbatch_normalization_37 (Batc (None, 8, 64, 64, 64)     256       \n_________________________________________________________________\nactivation_16 (Activation)   (None, 8, 64, 64, 64)     0         \n_________________________________________________________________\nmax_pooling3d_25 (MaxPooling (None, 4, 32, 32, 64)     0         \n_________________________________________________________________\nconv3d_29 (Conv3D)           (None, 4, 32, 32, 128)    65664     \n_________________________________________________________________\nbatch_normalization_38 (Batc (None, 4, 32, 32, 128)    512       \n_________________________________________________________________\nactivation_17 (Activation)   (None, 4, 32, 32, 128)    0         \n_________________________________________________________________\nmax_pooling3d_26 (MaxPooling (None, 2, 16, 16, 128)    0         \n_________________________________________________________________\nconv3d_30 (Conv3D)           (None, 2, 16, 16, 128)    131200    \n_________________________________________________________________\nbatch_normalization_39 (Batc (None, 2, 16, 16, 128)    512       \n_________________________________________________________________\nactivation_18 (Activation)   (None, 2, 16, 16, 128)    0         \n_________________________________________________________________\nmax_pooling3d_27 (MaxPooling (None, 1, 8, 8, 128)      0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 8192)              0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 256)               2097408   \n_________________________________________________________________\nbatch_normalization_40 (Batc (None, 256)               1024      \n_________________________________________________________________\ndense_7 (Dense)              (None, 1)                 257       \n=================================================================\nTotal params: 4,644,482\nTrainable params: 2,321,617\nNon-trainable params: 2,322,865\n_________________________________________________________________\nNone\nModel: \"AutoEncoderModel\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_9 (InputLayer)         [(None, 16, 128, 128, 3)] 0         \n_________________________________________________________________\nconv3d_31 (Conv3D)           (None, 16, 128, 128, 32)  2624      \n_________________________________________________________________\nbatch_normalization_41 (Batc (None, 16, 128, 128, 32)  128       \n_________________________________________________________________\nleaky_re_lu_21 (LeakyReLU)   (None, 16, 128, 128, 32)  0         \n_________________________________________________________________\nmax_pooling3d_28 (MaxPooling (None, 8, 64, 64, 32)     0         \n_________________________________________________________________\nconv3d_32 (Conv3D)           (None, 8, 64, 64, 48)     41520     \n_________________________________________________________________\nbatch_normalization_42 (Batc (None, 8, 64, 64, 48)     192       \n_________________________________________________________________\nleaky_re_lu_22 (LeakyReLU)   (None, 8, 64, 64, 48)     0         \n_________________________________________________________________\nmax_pooling3d_29 (MaxPooling (None, 4, 32, 32, 48)     0         \n_________________________________________________________________\nconv3d_33 (Conv3D)           (None, 4, 32, 32, 64)     83008     \n_________________________________________________________________\nbatch_normalization_43 (Batc (None, 4, 32, 32, 64)     256       \n_________________________________________________________________\nleaky_re_lu_23 (LeakyReLU)   (None, 4, 32, 32, 64)     0         \n_________________________________________________________________\nmax_pooling3d_30 (MaxPooling (None, 2, 16, 16, 64)     0         \n_________________________________________________________________\nconv3d_34 (Conv3D)           (None, 2, 16, 16, 64)     110656    \n_________________________________________________________________\nbatch_normalization_44 (Batc (None, 2, 16, 16, 64)     256       \n_________________________________________________________________\nleaky_re_lu_24 (LeakyReLU)   (None, 2, 16, 16, 64)     0         \n_________________________________________________________________\nmax_pooling3d_31 (MaxPooling (None, 2, 16, 16, 64)     0         \n_________________________________________________________________\nconv3d_transpose_9 (Conv3DTr (None, 4, 32, 32, 48)     24624     \n_________________________________________________________________\nbatch_normalization_45 (Batc (None, 4, 32, 32, 48)     192       \n_________________________________________________________________\nleaky_re_lu_25 (LeakyReLU)   (None, 4, 32, 32, 48)     0         \n_________________________________________________________________\nconv3d_transpose_10 (Conv3DT (None, 8, 64, 64, 32)     12320     \n_________________________________________________________________\nbatch_normalization_46 (Batc (None, 8, 64, 64, 32)     128       \n_________________________________________________________________\nleaky_re_lu_26 (LeakyReLU)   (None, 8, 64, 64, 32)     0         \n_________________________________________________________________\nconv3d_transpose_11 (Conv3DT (None, 16, 128, 128, 32)  8224      \n_________________________________________________________________\nbatch_normalization_47 (Batc (None, 16, 128, 128, 32)  128       \n_________________________________________________________________\nleaky_re_lu_27 (LeakyReLU)   (None, 16, 128, 128, 32)  0         \n_________________________________________________________________\nconv3d_35 (Conv3D)           (None, 16, 128, 128, 3)   2595      \n_________________________________________________________________\nactivation_19 (Activation)   (None, 16, 128, 128, 3)   0         \n=================================================================\nTotal params: 286,851\nTrainable params: 286,211\nNon-trainable params: 640\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"gan.test('../input/anomaly-detection-dev-set/ValidSet/',16)","execution_count":16,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"in converted code:\n\n    <ipython-input-12-52946881a849>:112 None  *\n        ds = ds.map(lambda x: _my_parser(x, batch_size=batch_size),\n\n    TypeError: tf___my_parser() missing 1 required positional argument: 'label'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-3095a01c73a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/anomaly-detection-dev-set/ValidSet/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-b5093a7ad812>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, dev_set_path, mini_batch_size)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev_set_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mdev_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuild_test_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_set_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mno_of_minibatches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mans_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-52946881a849>\u001b[0m in \u001b[0;36mbuild_test_dataset\u001b[0;34m(dir_path, batch_size, file_buffer)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# parse the records into the correct types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     ds = ds.map(lambda x: _my_parser(x, batch_size=batch_size),\n\u001b[0;32m--> 113\u001b[0;31m                 num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m       return ParallelMapDataset(\n\u001b[0;32m-> 1591\u001b[0;31m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3924\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3926\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3927\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3928\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 2395\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2396\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3139\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: in converted code:\n\n    <ipython-input-12-52946881a849>:112 None  *\n        ds = ds.map(lambda x: _my_parser(x, batch_size=batch_size),\n\n    TypeError: tf___my_parser() missing 1 required positional argument: 'label'\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}