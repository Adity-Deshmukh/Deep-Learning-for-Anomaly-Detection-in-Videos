{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.1.0 in /opt/conda/lib/python3.7/site-packages (2.1.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.14.0)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.0.8)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.2.0)\r\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (3.11.4)\r\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.11.2)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (3.2.1)\r\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.4.1)\r\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.8.1)\r\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (2.1.1)\r\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.28.1)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.18.1)\r\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.34.2)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.1.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.1.0)\r\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.2.2)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (2.1.0)\r\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.9.0)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.14.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.4.5.1)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.9)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.2.0)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.1)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\r\n",
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.1.0\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/saved-models/weights_epoch13.h5\n",
      "/kaggle/input/saved-models/weights_epoch4.h5\n",
      "/kaggle/input/saved-models/weights_epoch10_leaky_relu.h5\n",
      "/kaggle/input/saved-models/weights_epoch35.h5\n",
      "/kaggle/input/saved-models/weights_leaky_relu_epoch30.h5\n",
      "/kaggle/input/saved-models/weights_epoch25.h5\n",
      "/kaggle/input/saved-models/weights_leaky_relu_epoch20.h5\n",
      "/kaggle/input/saved-models/weights_epoch45.h5\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data9.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data2.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data24.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data6.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data34.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data14.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data38.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data0.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data41.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data36.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data4.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data42.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data27.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data21.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data39.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data5.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data37.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data26.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data19.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data31.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data30.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data40.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data33.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data3.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data32.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data20.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data18.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data29.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data16.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data8.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data17.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data22.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data13.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data7.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data11.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data28.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data1.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data15.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data12.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data23.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data35.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data10.tfrecord\n",
      "/kaggle/input/ucf-crime-training-subset/tfrecords2/Data25.tfrecord\n",
      "/kaggle/input/normal-videos-for-checking-autoencoder/minibatches/minibatch2.npz\n",
      "/kaggle/input/normal-videos-for-checking-autoencoder/minibatches/minibatch3.npz\n",
      "/kaggle/input/normal-videos-for-checking-autoencoder/minibatches/minibatch4.npz\n",
      "/kaggle/input/normal-videos-for-checking-autoencoder/minibatches/minibatch5.npz\n",
      "/kaggle/input/normal-videos-for-checking-autoencoder/minibatches/minibatch6.npz\n",
      "/kaggle/input/normal-videos-for-checking-autoencoder/minibatches/minibatch1.npz\n",
      "/kaggle/input/normal-videos-for-checking-autoencoder/minibatches/minibatch0.npz\n",
      "/kaggle/input/normal-videos-for-checking-autoencoder/minibatches/minibatch7.npz\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data55.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data53.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data45.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data34.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data47.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data38.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data57.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data48.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data0.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data41.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data60.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data49.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data58.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data42.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data46.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data51.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data27.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data39.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data56.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data37.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data31.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data30.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data40.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data33.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data32.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data18.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data54.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data50.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data28.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data59.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data35.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data52.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data43.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data25.tfrecord\n",
      "/kaggle/input/anomaly-detection-dev-set/ValidSet/Data44.tfrecord\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: |https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Corresponding changes are to be made here\n",
    "# if the feature description in tf2_preprocessing.py\n",
    "# is changed\n",
    "feature_description = {\n",
    "    'segment': tf.io.FixedLenFeature([], tf.string),\n",
    "    'file': tf.io.FixedLenFeature([], tf.string),\n",
    "    'num': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "\n",
    "def build_dataset(dir_path, batch_size=16, file_buffer=500*1024*1024,\n",
    "                  shuffle_buffer=1024, label=1):\n",
    "    '''Return a tf.data.Dataset based on all TFRecords in dir_path\n",
    "    Args:\n",
    "    dir_path: path to directory containing the TFRecords\n",
    "    batch_size: size of batch ie #training examples per element of the dataset\n",
    "    file_buffer: for TFRecords, size in bytes\n",
    "    shuffle_buffer: #examples to buffer while shuffling\n",
    "    label: target label for the example\n",
    "    '''\n",
    "    # glob pattern for files\n",
    "    file_pattern = os.path.join(dir_path, '*.tfrecord')\n",
    "    # stores shuffled filenames\n",
    "    file_ds = tf.data.Dataset.list_files(file_pattern)\n",
    "    # read from multiple files in parallel\n",
    "    ds = tf.data.TFRecordDataset(file_ds,\n",
    "                                 num_parallel_reads=tf.data.experimental.AUTOTUNE,\n",
    "                                 buffer_size=file_buffer)\n",
    "    # randomly draw examples from the shuffle buffer\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer,\n",
    "                    reshuffle_each_iteration=True)\n",
    "    # batch the examples\n",
    "    # dropping remainder for now, trouble when parsing - adding labels\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    # parse the records into the correct types\n",
    "    ds = ds.map(lambda x: _my_parser(x, label, batch_size),\n",
    "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def _my_parser(examples, label, batch_size):\n",
    "    '''Parses a batch of serialised tf.train.Example(s)\n",
    "    Args:\n",
    "    example: a batch serialised tf.train.Example(s)\n",
    "    Returns:\n",
    "    a tuple (segment, label)\n",
    "    where segment is a tensor of shape (#in_batch, #frames, h, w, #channels)\n",
    "    '''\n",
    "    # ex will be a tensor of serialised tensors\n",
    "    ex = tf.io.parse_example(examples, features=feature_description)\n",
    "    ex['segment'] = tf.map_fn(lambda x: _parse_segment(x),\n",
    "                              ex['segment'], dtype=tf.uint8)\n",
    "    # ignoring filename and segment num for now\n",
    "    # returns a tuple (tensor1, tensor2)\n",
    "    # tensor1 is a batch of segments, tensor2 is the corresponding labels\n",
    "    return (ex['segment'], tf.fill((batch_size, 1), label))\n",
    "\n",
    "\n",
    "def _parse_segment(segment):\n",
    "    '''Parses a segment and returns it as a tensor\n",
    "    A segment is a serialised tensor of a number of encoded jpegs\n",
    "    '''\n",
    "    # now a tensor of encoded jpegs\n",
    "    parsed = tf.io.parse_tensor(segment, out_type=tf.string)\n",
    "    # now a tensor of shape (#frames, h, w, #channels)\n",
    "    parsed = tf.map_fn(lambda y: tf.io.decode_jpeg(y), parsed, dtype=tf.uint8)\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def display_segment(segment, batch_size):\n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "    columns = int(math.sqrt(batch_size))\n",
    "    rows = math.ceil(batch_size / float(columns))\n",
    "    for i in range(1, columns*rows + 1):\n",
    "        img = segment[i-1]\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "test_feature_description = {\n",
    "    'segment': tf.io.FixedLenFeature([], tf.string),\n",
    "    'file': tf.io.FixedLenFeature([], tf.string),\n",
    "    'num': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "\n",
    "def build_test_dataset(dir_path, batch_size=16, file_buffer=500*1024*1024):\n",
    "    '''Return a tf.data.Dataset based on all TFRecords in dir_path\n",
    "    Args:\n",
    "    dir_path: path to directory containing the TFRecords\n",
    "    batch_size: size of batch ie #training examples per element of the dataset\n",
    "    file_buffer: for TFRecords, size in bytes\n",
    "    label: target label for the example\n",
    "    '''\n",
    "    # glob pattern for files\n",
    "    file_pattern = os.path.join(dir_path, '*.tfrecord')\n",
    "    # stores shuffled filenames\n",
    "    file_ds = tf.data.Dataset.list_files(file_pattern)\n",
    "    # read from multiple files in parallel\n",
    "    ds = tf.data.TFRecordDataset(file_ds,\n",
    "                                 num_parallel_reads=tf.data.experimental.AUTOTUNE,\n",
    "                                 buffer_size=file_buffer)\n",
    "    # batch the examples\n",
    "    # dropping remainder for now, trouble when parsing - adding labels\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    # parse the records into the correct types\n",
    "    ds = ds.map(lambda x: _my_test_parser(x, batch_size=batch_size),\n",
    "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def _my_test_parser(examples, batch_size):\n",
    "    '''Parses a batch of serialised tf.train.Example(s)\n",
    "    Args:\n",
    "    example: a batch serialised tf.train.Example(s)\n",
    "    Returns:\n",
    "    a tuple (segment, label)\n",
    "    where segment is a tensor of shape (#in_batch, #frames, h, w, #channels)\n",
    "    '''\n",
    "    # ex will be a tensor of serialised tensors\n",
    "    ex = tf.io.parse_example(examples, features=test_feature_description)\n",
    "    ex['segment'] = tf.map_fn(lambda x: _parse_segment(x),\n",
    "                              ex['segment'], dtype=tf.uint8)\n",
    "    # ignoring filename and segment num for now\n",
    "    # returns a tuple (tensor1, tensor2)\n",
    "    # tensor1 is a batch of segments, tensor2 is the corresponding labels\n",
    "    return (ex['segment'], ex['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AutoEncoderModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16, 128, 128, 3)] 0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 16, 128, 128, 32)  2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16, 128, 128, 32)  128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 16, 128, 128, 32)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 8, 64, 64, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 8, 64, 64, 48)     41520     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 64, 64, 48)     192       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 8, 64, 64, 48)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 4, 32, 32, 48)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 4, 32, 32, 64)     83008     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 32, 32, 64)     256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 4, 32, 32, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 16, 16, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 2, 16, 16, 64)     110656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 16, 16, 64)     256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 2, 16, 16, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 16, 16, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose (Conv3DTran (None, 4, 32, 32, 48)     24624     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 32, 32, 48)     192       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 32, 32, 48)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTr (None, 8, 64, 64, 32)     12320     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 64, 64, 32)     128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 64, 64, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTr (None, 16, 128, 128, 32)  8224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 128, 128, 32)  128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 128, 128, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 16, 128, 128, 3)   2595      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16, 128, 128, 3)   0         \n",
      "=================================================================\n",
      "Total params: 286,851\n",
      "Trainable params: 286,211\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (Input, Activation,\n",
    "                                     BatchNormalization, Conv3D,\n",
    "                                     LeakyReLU, Conv3DTranspose)\n",
    "from tensorflow.keras.layers import MaxPool3D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def AutoEncoderModel():\n",
    "    # encoder\n",
    "    X_input = Input((16, 128, 128, 3))\n",
    "\n",
    "    X = Conv3D(32, 3, padding='same')(X_input)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LeakyReLU()(X)\n",
    "    X = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(X)\n",
    "    # current shape is 8x64x64x32\n",
    "    X = Conv3D(48, 3, padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LeakyReLU()(X)\n",
    "    X = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(X)\n",
    "    # current shape is 4x32x32x48\n",
    "    X = Conv3D(64, 3, padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LeakyReLU()(X)\n",
    "    X = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(X)\n",
    "    # current shape is 2x16x16x64\n",
    "    X = Conv3D(64, 3, padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LeakyReLU()(X)\n",
    "    X = MaxPool3D(pool_size=(2, 2, 2), strides=(1, 1, 1), padding='same')(X)\n",
    "    # current shape is 2x16x16x64\n",
    "    # decoder\n",
    "\n",
    "    X = Conv3DTranspose(48, 2, strides=(2, 2, 2), padding='valid')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LeakyReLU()(X)\n",
    "    # current shape is 4x32x32x48\n",
    "    X = Conv3DTranspose(32, 2, strides=(2, 2, 2), padding='valid')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LeakyReLU()(X)\n",
    "    # current shape is 8x64x64x32\n",
    "    X = Conv3DTranspose(32, 2, strides=(2, 2, 2), padding='valid')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = LeakyReLU()(X)\n",
    "    # current shape is 16x128x128x32\n",
    "    X = Conv3D(3, 3, strides=(1, 1, 1), padding='same')(X)\n",
    "    X = Activation('sigmoid')(X)\n",
    "    # current shape is 16x128x128x3\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='AutoEncoderModel')\n",
    "    return model\n",
    "\n",
    "\n",
    "def custom_loss(new, original):\n",
    "    reconstruction_error = K.mean(K.square(new-original))\n",
    "    return reconstruction_error\n",
    "\n",
    "autoEncoderModel = AutoEncoderModel()\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "autoEncoderModel.compile(\n",
    "    loss=custom_loss, optimizer=opt, metrics=['accuracy'])\n",
    "print(autoEncoderModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_5 (Conv3D)            (None, 16, 128, 128, 48)  1200      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 128, 128, 48)  192       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 16, 128, 128, 48)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 8, 64, 64, 48)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 8, 64, 64, 64)     24640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 64, 64, 64)     256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 8, 64, 64, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 4, 32, 32, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 4, 32, 32, 128)    65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 32, 32, 128)    512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 4, 32, 32, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 2, 16, 16, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 2, 16, 16, 128)    131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 16, 16, 128)    512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 2, 16, 16, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 1, 8, 8, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,322,865\n",
      "Trainable params: 2,321,617\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.layers import Flatten,Dense\n",
    "from tensorflow.keras import Sequential\n",
    "def create_discriminator_model():\n",
    "\n",
    "    X_input = Input((16, 128, 128, 3))\n",
    "\n",
    "    # not sure about the axis in batch norm\n",
    "    # do we also add dropout after batchnorm/pooling?\n",
    "\n",
    "    # Convolutional Layers\n",
    "    # changed the no of filters\n",
    "    model= Sequential()\n",
    "    model.add(Conv3D(filters=48, kernel_size=(2, 2, 2), padding=\"same\",input_shape=(16, 128, 128, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n",
    "\n",
    "    model.add(Conv3D(filters=64, kernel_size=(2, 2, 2), padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n",
    "\n",
    "    model.add(Conv3D(filters=128, kernel_size=(2, 2, 2), padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n",
    "\n",
    "    model.add(Conv3D(filters=128, kernel_size=(2, 2, 2), padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n",
    "\n",
    "    # to add the 5th layer change the cap to 32 frames\n",
    "\n",
    "    # X=Conv3D(filters=256,kernel_size=(2,2,2),padding=\"same\")(X)\n",
    "    # X=BatchNormalization()(X)\n",
    "    # X=Activation('relu')(X)\n",
    "    # X=MaxPool3D(pool_size=(2,2,2),strides=(2,2,2))(X)\n",
    "\n",
    "    # Fully connected layers\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    # add batch norm to dense layer\n",
    "    model.add(BatchNormalization())\n",
    "    # activation done with loss fn\n",
    "    # for numerical stability\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "discriminator = create_discriminator_model()\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "loss = BinaryCrossentropy()\n",
    "discriminator.compile(loss=loss,\n",
    "                      optimizer=opt,\n",
    "                      metrics=['accuracy'])\n",
    "print(discriminator.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 16, 128, 128, 3)] 0         \n",
      "_________________________________________________________________\n",
      "AutoEncoderModel (Model)     (None, 16, 128, 128, 3)   286851    \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 2322865   \n",
      "=================================================================\n",
      "Total params: 2,609,716\n",
      "Trainable params: 286,211\n",
      "Non-trainable params: 2,323,505\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_9 (Conv3D)            (None, 16, 128, 128, 48)  1200      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16, 128, 128, 48)  192       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 16, 128, 128, 48)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 8, 64, 64, 48)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 8, 64, 64, 64)     24640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8, 64, 64, 64)     256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 8, 64, 64, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 4, 32, 32, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 4, 32, 32, 128)    65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4, 32, 32, 128)    512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 4, 32, 32, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 2, 16, 16, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 2, 16, 16, 128)    131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 2, 16, 16, 128)    512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 2, 16, 16, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 1, 8, 8, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 4,644,482\n",
      "Trainable params: 2,321,617\n",
      "Non-trainable params: 2,322,865\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"AutoEncoderModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 16, 128, 128, 3)] 0         \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 16, 128, 128, 32)  2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 16, 128, 128, 32)  128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 16, 128, 128, 32)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 8, 64, 64, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 8, 64, 64, 48)     41520     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8, 64, 64, 48)     192       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 8, 64, 64, 48)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling (None, 4, 32, 32, 48)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 4, 32, 32, 64)     83008     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 4, 32, 32, 64)     256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 4, 32, 32, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 2, 16, 16, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_16 (Conv3D)           (None, 2, 16, 16, 64)     110656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 2, 16, 16, 64)     256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 2, 16, 16, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 2, 16, 16, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_3 (Conv3DTr (None, 4, 32, 32, 48)     24624     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 4, 32, 32, 48)     192       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 4, 32, 32, 48)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_4 (Conv3DTr (None, 8, 64, 64, 32)     12320     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 8, 64, 64, 32)     128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 8, 64, 64, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_5 (Conv3DTr (None, 16, 128, 128, 32)  8224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 16, 128, 128, 32)  128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 16, 128, 128, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 16, 128, 128, 3)   2595      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 128, 128, 3)   0         \n",
      "=================================================================\n",
      "Total params: 286,851\n",
      "Trainable params: 286,211\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from cv2 import VideoWriter, VideoWriter_fourcc\n",
    "class GAN():\n",
    "    def __init__(self, mini_batch_size):\n",
    "        self.image_shape=(16,128,128,3)\n",
    "        learning_rate=0.003\n",
    "        opt=keras.optimizers.Adam(lr=learning_rate)\n",
    "        opt1=keras.optimizers.Adam(lr=learning_rate)\n",
    "        opt_slow=keras.optimizers.Adam(lr=0.01)\n",
    "        #Build and compile the discriminator\n",
    "        self.discriminator=create_discriminator_model()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy',tf.keras.metrics.TruePositives(),tf.keras.metrics.FalsePositives(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.FalseNegatives()])\n",
    "        #Build and compile the generator\n",
    "        self.generator=AutoEncoderModel()\n",
    "        self.generator.compile(loss='mse',optimizer=opt_slow)\n",
    "\n",
    "        #the generator takes a video as input and generates a modified video\n",
    "        z = Input(shape=(self.image_shape))\n",
    "        img = self.generator(z)\n",
    "        self.discriminator.trainable = False\n",
    "        validity = self.discriminator(img)\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=opt1,metrics=['accuracy',tf.keras.metrics.TruePositives(),tf.keras.metrics.FalsePositives(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.FalseNegatives()])\n",
    "        self.dir_path = '/kaggle/input/ucf-crime-training-subset/tfrecords2/'\n",
    "        self.ds = build_dataset(self.dir_path, batch_size=mini_batch_size,file_buffer=512*1024)\n",
    "    \n",
    "    def train(self,epochs,mini_batch_size):\n",
    "        #this function will need to be added later\n",
    "        tf.summary.trace_off()\n",
    "        for epoch in range(epochs):\n",
    "            d_loss_sum=tf.zeros(6)\n",
    "            reconstruct_error_sum=0\n",
    "            g_loss_sum=tf.zeros(6)\n",
    "            no_of_minibatches=0\n",
    "            for minibatch,labels in self.ds:\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                #normalize inputs\n",
    "                no_of_minibatches+=1\n",
    "                minibatch=tf.cast(tf.math.divide(minibatch,255), tf.float32)\n",
    "                gen_vids=self.generator.predict(minibatch)\n",
    "                #might have to combine these to improve batch norm\n",
    "                self.discriminator.trainable = True\n",
    "                d_loss_real=self.discriminator.train_on_batch(minibatch,tf.ones((mini_batch_size,1)))\n",
    "                d_loss_fake=self.discriminator.train_on_batch(gen_vids,tf.zeros((mini_batch_size,1)))\n",
    "                d_loss=0.5*tf.math.add(d_loss_real,d_loss_fake)\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "                # The generator wants the discriminator to label the generated samples as valid (ones)\n",
    "                self.discriminator.trainable = False\n",
    "                valid_y = tf.ones((mini_batch_size,1))\n",
    "                # Train the generator\n",
    "                g_loss = self.combined.train_on_batch(minibatch,valid_y)\n",
    "                reconstruct_error=self.generator.train_on_batch(minibatch,minibatch)\n",
    "                d_loss_sum+=d_loss\n",
    "                g_loss_sum+=g_loss\n",
    "                reconstruct_error_sum+=reconstruct_error\n",
    "            print(no_of_minibatches)\n",
    "            self.combined.save_weights('/kaggle/working/weights_epoch%d.h5' %(epoch+21))\n",
    "            g_loss=g_loss_sum/no_of_minibatches\n",
    "            d_loss=d_loss_sum/no_of_minibatches\n",
    "            reconstruct_error=reconstruct_error_sum/no_of_minibatches\n",
    "            # Plot the progress\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f, accuracy %.2f%% from which %f is combined loss and %f is reconstruction loss]\" % (epoch+21, d_loss[0], 100*d_loss[1], g_loss[0]+reconstruct_error,g_loss[1]*100,g_loss[0],reconstruct_error))\n",
    "        tf.summary.trace_on()\n",
    "    \n",
    "    def test(self,dev_set_path,mini_batch_size):\n",
    "        dev_set=build_test_dataset(dev_set_path,batch_size=mini_batch_size,file_buffer=500*1024)\n",
    "        no_of_minibatches=0\n",
    "        ans_c=tf.zeros(6)\n",
    "        ans_d=tf.zeros(6)\n",
    "        for minibatch,labels in dev_set:\n",
    "            no_of_minibatches+=1\n",
    "            ans_c=self.combined.test_on_batch(minibatch,(labels==0),reset_metrics=(no_of_minibatches==1))\n",
    "            ans_d=self.combined.test_on_batch(minibatch,(labels==0),reset_metrics=(no_of_minibatches==1))\n",
    "        print(\"Tested Normal vs Anomaly on %d minibatches\" %(no_of_minibatches))\n",
    "        print(\"For Combined Model: loss %f accuracy %.2f%% , TP- %d, FP- %d, TN- %d, FN - %d\" %(ans_c[0],ans_c[1]*100,ans_c[2],ans_c[3],ans_c[4],ans_c[5]))\n",
    "        print(\"For Discriminator: loss %f accuracy %.2f%% , TP- %d, FP- %d, TN- %d, FN - %d\" %(ans_d[0],ans_d[1]*100,ans_d[2],ans_d[3],ans_d[4],ans_d[5]))\n",
    "    \n",
    "    def test_real_vs_fake(self,dev_set_path,mini_batch_size):\n",
    "        dev_set=build_dataset(dev_set_path,batch_size=mini_batch_size,file_buffer=500*1024)\n",
    "        ans_c=tf.zeros(6)\n",
    "        ans_d=tf.zeros(6)\n",
    "        no_of_minibatches=0\n",
    "        for minibatch,labels in dev_set:\n",
    "            no_of_minibatches+=1\n",
    "            ans_c=self.combined.test_on_batch(minibatch,labels,reset_metrics=(no_of_minibatches==1))\n",
    "            ans_d=self.discriminator.test_on_batch(minibatch,labels,reset_metrics=(no_of_minibatches==1))\n",
    "            fake_vals=np.random.random((mini_batch_size,16,128,128,3))\n",
    "            ans_c=self.combined.test_on_batch(fake_vals,tf.zeros((mini_batch_size,1)),reset_metrics=False)\n",
    "            ans_d=self.discriminator.test_on_batch(fake_vals,tf.zeros((mini_batch_size,1)),reset_metrics=False)\n",
    "        print(\"Tested Real Vs Fake on %d minibatches\" %(no_of_minibatches))\n",
    "        print(\"For Combined Model: loss %f accuracy %.2f%% , TP- %d, FP- %d, TN- %d, FN - %d\" %(ans_c[0],ans_c[1]*100,ans_c[2],ans_c[3],ans_c[4],ans_c[5]))\n",
    "        print(\"For Discriminator: loss %f accuracy %.2f%% , TP- %d, FP- %d, TN- %d, FN - %d\" %(ans_d[0],ans_d[1]*100,ans_d[2],ans_d[3],ans_d[4],ans_d[5]))\n",
    "        \n",
    "        \n",
    "    def visualise_autoencoder_outputs(self,no_of_minibatches):\n",
    "        fourcc = VideoWriter_fourcc(*'MP42') #some code required for VideoWriter\n",
    "        video = VideoWriter('/kaggle/working/reconstructed_video.avi', fourcc, float(24), (128, 128)) #creates video to store 1st segment\n",
    "        for i in range(no_of_minibatches):\n",
    "            inp=np.load(\"../input/normal-videos-for-checking-autoencoder/minibatches/minibatch%d.npz\" % (i))\n",
    "            inp=inp['arr_0']\n",
    "            inp=tf.cast(tf.math.divide(inp,255), tf.float32)\n",
    "            gen_vids=self.generator.predict(inp)\n",
    "            gen_vids*=255\n",
    "            for j in range(16):\n",
    "                for k in range(16):\n",
    "                    frame = np.uint8(gen_vids[j][k])\n",
    "                    video.write(frame)\n",
    "        print(\"Done! Reconstructed Video is now available\")\n",
    "                    \n",
    "                    \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "# BATCH SIZE WAS MOVED TO INIT, PROBABLY NOT THE BEST WAY TO DO IT\n",
    "gan = GAN(16)\n",
    "gan.combined.load_weights('../input/saved-models/weights_leaky_relu_epoch30.h5')\n",
    "print(gan.combined.summary())\n",
    "print(gan.discriminator.summary())\n",
    "print(gan.generator.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1325\n",
      "21 [D loss: 0.693183, acc.: 47.78%] [G loss: 0.702800, accuracy 80.80% from which 0.692514 is combined loss and 0.010285 is reconstruction loss]\n",
      "1325\n",
      "22 [D loss: 0.693181, acc.: 33.92%] [G loss: 0.700350, accuracy 36.49% from which 0.693177 is combined loss and 0.007173 is reconstruction loss]\n",
      "1325\n",
      "23 [D loss: 0.693180, acc.: 15.90%] [G loss: 0.699600, accuracy 15.81% from which 0.693184 is combined loss and 0.006415 is reconstruction loss]\n",
      "1325\n",
      "24 [D loss: 0.693181, acc.: 4.66%] [G loss: 0.699063, accuracy 5.48% from which 0.693182 is combined loss and 0.005881 is reconstruction loss]\n",
      "1325\n",
      "25 [D loss: 0.693180, acc.: 0.87%] [G loss: 0.698704, accuracy 0.77% from which 0.693181 is combined loss and 0.005523 is reconstruction loss]\n",
      "1325\n",
      "26 [D loss: 0.693181, acc.: 0.14%] [G loss: 0.698478, accuracy 0.19% from which 0.693181 is combined loss and 0.005297 is reconstruction loss]\n",
      "1325\n",
      "27 [D loss: 0.693181, acc.: 0.00%] [G loss: 0.698279, accuracy 0.00% from which 0.693181 is combined loss and 0.005098 is reconstruction loss]\n",
      "1325\n",
      "28 [D loss: 0.693181, acc.: 0.00%] [G loss: 0.698181, accuracy 0.00% from which 0.693181 is combined loss and 0.005000 is reconstruction loss]\n",
      "1325\n",
      "29 [D loss: 0.693181, acc.: 0.00%] [G loss: 0.698064, accuracy 0.00% from which 0.693181 is combined loss and 0.004883 is reconstruction loss]\n",
      "1325\n",
      "30 [D loss: 0.693181, acc.: 0.00%] [G loss: 0.697941, accuracy 0.00% from which 0.693181 is combined loss and 0.004761 is reconstruction loss]\n",
      "Tested Normal vs Anomaly on 1080 minibatches\n",
      "For Combined Model: loss 0.693195 accuracy 3.41% , TP- 0, FP- 0, TN- 1178, FN - 33334\n",
      "For Discriminator: loss 0.693195 accuracy 3.41% , TP- 0, FP- 0, TN- 1178, FN - 33350\n",
      "Tested Real Vs Fake on 1080 minibatches\n",
      "For Combined Model: loss 0.693105 accuracy 50.02% , TP- 0, FP- 0, TN- 17280, FN - 17264\n",
      "For Discriminator: loss 0.693103 accuracy 55.30% , TP- 1823, FP- 0, TN- 17280, FN - 15441\n",
      "Done! Reconstructed Video is now available\n"
     ]
    }
   ],
   "source": [
    "gan.train(10,16)\n",
    "gan.test('../input/anomaly-detection-dev-set/ValidSet',16)\n",
    "gan.test_real_vs_fake('../input/anomaly-detection-dev-set/ValidSet',16)\n",
    "gan.visualise_autoencoder_outputs(8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
